# TCM Embedding Model

## å°ˆæ¡ˆæ¦‚è¿°

æœ¬å°ˆæ¡ˆåˆ©ç”¨ Qwen3-Embedding å’Œ Qwen3-Reranker æ¨¡å‹ï¼Œé€é TCM-SD è³‡æ–™é›†é€²è¡Œå¾®èª¿ï¼Œå»ºç«‹å°ˆé–€é‡å°å‚³çµ±ä¸­é†«è­‰å‹è¨ºæ–·çš„é«˜å“è³ªåµŒå…¥å’Œé‡æ’åºæ¨¡å‹ã€‚

## ç›®æ¨™åŠŸèƒ½

- ğŸ¥ **ä¸­é†«é ˜åŸŸç‰¹åŒ–**ï¼šé‡å°ä¸­é†«è¡“èªã€è¨ºæ–·ã€æ–¹åŠ‘ç­‰å°ˆæ¥­å…§å®¹å„ªåŒ–
- ğŸ” **èªç¾©æª¢ç´¢**ï¼šæä¾›ç²¾ç¢ºçš„ä¸­é†«æ–‡ç»å’ŒçŸ¥è­˜æª¢ç´¢èƒ½åŠ›  
- ğŸš€ **é«˜æ•ˆè¨“ç·´**ï¼šåŸºæ–¼ ms-swift æ¡†æ¶çš„é«˜æ•ˆ fine-tuning æµç¨‹
- ğŸ˜· **ç—…ä¾‹å°è­‰å‹å¾®èª¿**ï¼šåœ¨ TCM-SD è³‡æ–™é›†ä¸ŠæˆåŠŸå®Œæˆ fine-tuning

## ç’°å¢ƒéœ€æ±‚

### ç³»çµ±è¦æ±‚
- Python >= 3.10
- [uv](https://docs.astral.sh/uv/) - ç¾ä»£ Python åŒ…ç®¡ç†å·¥å…·
- CUDA >= 11.8 (æ¨è–¦ä½¿ç”¨ GPU è¨“ç·´)
- è¨˜æ†¶é«”ï¼šå»ºè­° 32GB+ RAM
- ç¡¬ç¢Ÿç©ºé–“ï¼šè‡³å°‘ 100GB å¯ç”¨ç©ºé–“

### ç¡¬é«”å»ºè­°
- **è¨“ç·´ç’°å¢ƒ**ï¼šNVIDIA GPU (V100/A6000/H100 æˆ–æ›´é«˜)
- **æ¨ç†ç’°å¢ƒ**ï¼šå¯åœ¨ CPU ä¸Šé‹è¡Œï¼ŒGPU å¯æå‡æ•ˆèƒ½
> **å‚™è¨»**: å»ºè­°ä½¿ç”¨ Ampere æ¶æ§‹ï¼ˆA100/L40S/4090ï¼‰ä»¥ä¸Šçš„ GPUï¼Œå› ç‚ºæ”¯æ´ BF16 èˆ‡ FlashAttentionï¼Œå¯å¤§å¹…é™ä½è¨˜æ†¶é«”å ç”¨ä¸¦æå‡é€Ÿåº¦ã€‚

## å®‰è£æŒ‡å—

### 1. å®‰è£ uv
å¦‚æœæ‚¨é‚„æ²’æœ‰å®‰è£ uvï¼Œè«‹å…ˆå®‰è£ï¼š

```bash
# macOS å’Œ Linux
curl -LsSf https://astral.sh/uv/install.sh | sh

# æˆ–ä½¿ç”¨ pip å®‰è£
pip install uv
```

### 2. å…‹éš†å°ˆæ¡ˆ
```bash
git clone https://github.com/NightLightTw/TCMEmbeddingModel.git
cd TCMEmbeddingModel
```

### 3. ä½¿ç”¨ uv å®‰è£ç’°å¢ƒå’Œä¾è³´
```bash
# uv æœƒè‡ªå‹•å‰µå»ºè™›æ“¬ç’°å¢ƒä¸¦å®‰è£ä¾è³´
uv sync

# å¦‚æœéœ€è¦é–‹ç™¼ä¾è³´
uv sync --extra dev
```

### 4. æ¿€æ´»è™›æ“¬ç’°å¢ƒ
```bash
# æ¿€æ´»è™›æ“¬ç’°å¢ƒ
source .venv/bin/activate  # Linux/Mac
```

### 5. (å¯é¸)åŠ é€Ÿå·¥å…·
```bash
# Optional packages
uv pip install deepspeed # multi-GPU training
uv pip install liger-kernel # save GPU memory resources
uv pip install flash-attn --no-build-isolation
```

### Optional: Multi-Stage Sampler Extension

æœ¬å°ˆæ¡ˆæœ‰ä¸€å€‹è‡ªè¨‚åˆ†æ”¯ï¼ˆ`feature/3.8.2-multi-stage-sampler`ï¼‰æä¾›å¢å¼·ç‰ˆçš„å¤šéšæ®µå–æ¨£æ©Ÿåˆ¶ã€‚

```bash
uv pip install git+https://github.com/NightLightTw/ms-swift.git@feature/3.8.2-multi-stage-sampler
```

> âš ï¸ æ³¨æ„ï¼šæ­¤åˆ†æ”¯ç”± NightLightTw ç¶­è­·ï¼Œå¯èƒ½èˆ‡ä¸Šæ¸¸ç‰ˆæœ¬ä¸åŒã€‚åƒ…åœ¨éœ€è¦å¤šéšæ®µå–æ¨£åŠŸèƒ½æ™‚ä½¿ç”¨ã€‚

## é–‹ç™¼æŒ‡å—

### ä½¿ç”¨ uv é€²è¡Œé–‹ç™¼

```bash
# æ·»åŠ æ–°çš„ä¾è³´
uv add package-name

# æ·»åŠ é–‹ç™¼ä¾è³´
uv add --dev package-name

# ç§»é™¤ä¾è³´
uv remove package-name

# æ›´æ–°ä¾è³´
uv sync --upgrade

# é‹è¡Œè…³æœ¬
uv run python your_script.py

```

### è³‡æ–™æº–å‚™

- åŸå§‹è³‡æ–™éœ€è‡ªå®˜æ–¹ TCM-SD å°ˆæ¡ˆå–å¾—ï¼š[Borororo/ZY-BERT](https://github.com/Borororo/ZY-BERT)
> **æ³¨æ„**ï¼šå®˜æ–¹é‡‹å‡ºçš„ `train.json` ç­‰æª”æ¡ˆå¯¦éš›ç‚º JSON Lines æ ¼å¼ï¼Œè«‹æ”¹ç‚º `.jsonl` å‰¯æª”åå¾Œå†ä½¿ç”¨ï¼Œé¿å…è§£æå¤±æ•—ã€‚

è½‰æ›å·¥å…·æ”¯æŒå¤šç¨®æ•¸æ“šå¢å¼·ç­–ç•¥ï¼Œåƒè€ƒ `scripts/load_data.sh` æŸ¥çœ‹æ‰€æœ‰é¸é …ï¼š

```bash
# åŸºç¤æ ¼å¼ï¼ˆç„¡ç¡¬è² æ¨£æœ¬ï¼‰
uv run python scripts/convert_to_infonce.py \
    --input data/raw_data/TCM_SD/train.jsonl \
    --knowledge data/raw_data/TCM_SD/syndrome_knowledge.jsonl \
    --output data/train.jsonl

# ä½¿ç”¨ BM25 ç¡¬è² æ¨£æœ¬
uv run python scripts/convert_to_infonce.py \
    --input data/raw_data/TCM_SD/train.jsonl \
    --knowledge data/raw_data/TCM_SD/syndrome_knowledge.jsonl \
    --output data/train_with_hard_negatives.jsonl \
    --with-hard-negatives

# ä½¿ç”¨è‡ªå®šç¾© Embedding ç¡¬è² æ¨£æœ¬
uv run python scripts/convert_to_infonce.py \
    --input data/raw_data/TCM_SD/train.jsonl \
    --knowledge data/raw_data/TCM_SD/syndrome_knowledge.jsonl \
    --output data/train_with_hard_negatives_custom_embedding.jsonl \
    --with-hard-negatives-custom-embedding

# æ··åˆç¡¬è² æ¨£æœ¬ï¼ˆ2éš¨æ©Ÿ + 3BM25 + 3Embeddingï¼‰
uv run python scripts/convert_to_infonce.py \
    --input data/raw_data/TCM_SD/train.jsonl \
    --knowledge data/raw_data/TCM_SD/syndrome_knowledge.jsonl \
    --output data/train_hybrid.jsonl \
    --hybrid

# å­—æ®µçµ„åˆå¢å¼·ï¼ˆ11ç¨®çµ„åˆï¼‰
uv run python scripts/convert_to_infonce.py \
    --input data/raw_data/TCM_SD/train.jsonl \
    --knowledge data/raw_data/TCM_SD/syndrome_knowledge.jsonl \
    --output data/train_field_combinations.jsonl \
    --field-combinations \
    --with-hard-negatives

# æ’åˆ—å¢å¼·ï¼ˆzone-basedï¼Œ5å€æ•¸æ“šï¼‰
uv run python scripts/convert_to_infonce.py \
    --input data/raw_data/TCM_SD/train.jsonl \
    --knowledge data/raw_data/TCM_SD/syndrome_knowledge.jsonl \
    --output data/train_permutation_argument_x5.jsonl \
    --permutation-argument \
    --multiplier 5 \
    --with-hard-negatives

# é™åˆ¶æ¨£æœ¬æ•¸é‡ï¼ˆæ¸¬è©¦ç”¨ï¼‰
uv run python scripts/convert_to_infonce.py \
    --input data/raw_data/TCM_SD/train.jsonl \
    --knowledge data/raw_data/TCM_SD/syndrome_knowledge.jsonl \
    --output data/train_sample.jsonl \
    --max-samples 100
```

### é–‹å§‹è¨“ç·´

æœ¬å°ˆæ¡ˆä½¿ç”¨ [ms-swift](https://github.com/modelscope/ms-swift) æ¡†æ¶å° [Qwen3-Embedding](https://github.com/QwenLM/Qwen3-Embedding) æ¨¡å‹é€²è¡Œ fine-tuningã€‚

#### Embedding æ¨¡å‹è¨“ç·´

åƒè€ƒ `scripts/train.sh`ï¼š

```bash
export CUDA_VISIBLE_DEVICES=0,1
export NVIDIA_TF32_OVERRIDE=1
export INFONCE_USE_BATCH=true
export INFONCE_MASK_FAKE_NEGATIVE=true

NPROC_PER_NODE=2 \
swift sft \
  --model Qwen/Qwen3-Embedding-0.6B \
  --task_type embedding \
  --model_type qwen3_emb \
  --train_type full \
  --dataset data/train.jsonl \
  --val_dataset data/dev.jsonl \
  --output_dir output \
  --eval_strategy steps --eval_steps 100 \
  --num_train_epochs 5 \
  --per_device_train_batch_size 32 \
  --per_device_eval_batch_size 32 \
  --gradient_accumulation_steps 1 \
  --learning_rate 6e-6 \
  --loss_type infonce \
  --dataloader_drop_last true \
  --dataloader_num_workers 16 \
  --dataloader_persistent_workers true \
  --attn_impl flash_attn \
  --bf16 true \
  --use_hf true \
  --seed 42
```

#### Reranker æ¨¡å‹è¨“ç·´

```bash
# ä½¿ç”¨ç›¸åŒçš„ train.jsonl æ•¸æ“šï¼Œä½†æ”¹ç”¨ reranker ä»»å‹™é¡å‹
swift sft \
  --model Qwen/Qwen3-Reranker-4B \
  --task_type generative_reranker \
  --loss_type generative_reranker \
  --train_type full \
  --dataset data/train.jsonl \
  --val_dataset data/dev.jsonl \
  --output_dir output/reranker \
  --eval_strategy steps --eval_steps 100 \
  --num_train_epochs 5 \
  --per_device_train_batch_size 16 \
  --per_device_eval_batch_size 16 \
  --gradient_accumulation_steps 2 \
  --learning_rate 6e-6 \
  --dataloader_drop_last true \
  --bf16 true
```

### è¨“ç·´å»ºè­°
- `per_device_train_batch_size` å»ºè­°åœ¨ GPU è¨˜æ†¶é«”å…è¨±ä¸‹ç›¡é‡æ‹‰é«˜ï¼Œæå‡è¨“ç·´ç©©å®šåº¦
- è¨“ç·´ InfoNCE æ™‚ï¼Œå•Ÿç”¨ `INFONCE_USE_BATCH=true` å¯å°‡batchå…§çš„å…¶ä»–æ­£æ¨£æœ¬ä½œçˆ²è² æ¨£æœ¬ï¼Œæå‡å¤šæ¨£æ€§
- é…åˆ `INFONCE_MASK_FAKE_NEGATIVE=true` å¯é®è”½å‡é™°æ€§æ¨£æœ¬ï¼Œæå‡æ•ˆæœ
- ä½¿ç”¨ `--attn_impl flash_attn` å’Œ `--bf16 true` å¯å¤§å¹…æå‡è¨“ç·´é€Ÿåº¦ï¼ˆéœ€ Ampere æ¶æ§‹ä»¥ä¸Š GPUï¼‰
- `--dataloader_persistent_workers true` å¯æ¸›å°‘ dataloader é‡å•Ÿé–‹éŠ·

### æ¨¡å‹éƒ¨ç½²èˆ‡æ¨ç†

#### Embedding æ¨¡å‹éƒ¨ç½²

åƒè€ƒ `scripts/deploy.sh`ï¼š

```bash
# ä½¿ç”¨éƒ¨ç½²è…³æœ¬é€²è¡Œæ¨¡å‹æœå‹™éƒ¨ç½² (scripts/deploy.sh)
swift deploy \
  --ckpt_dir ../output/my-training/checkpoint-xxx \
  --served_model_name Qwen3-Embedding-0.6B-finetuned \
  --task_type embedding \
  --infer_backend vllm \
  --torch_dtype float16

# ä½¿ç”¨vllmé€²è¡Œéƒ¨ç½²
vllm serve ../output/my-training/checkpoint-xxx \
  --served_model_name Qwen3-Embedding-0.6B-finetuned

# éƒ¨ç½²åŸå§‹ç‰ˆæœ¬æ¨¡å‹
swift deploy \
  --model Qwen/Qwen3-Embedding-0.6B \
  --served_model_name Qwen3-Embedding-0.6B-base \
  --task_type embedding \
  --infer_backend vllm \
  --torch_dtype float16
```

#### Reranker æ¨¡å‹éƒ¨ç½²

åƒè€ƒ `scripts/deploy_rerank.sh`ï¼š

```bash
export CUDA_VISIBLE_DEVICES=1

# ä½¿ç”¨ vllm éƒ¨ç½² Rerankerï¼ˆswift<3.9 æœ‰ bugï¼Œç›´æ¥ç”¨ vllmï¼‰
vllm serve output/reranker/my-training/checkpoint-xxx \
   --hf_overrides '{"architectures": ["Qwen3ForSequenceClassification"],"classifier_from_token": ["no", "yes"],"is_original_qwen3_reranker": true}' \
   --port 8001 \
   --host 0.0.0.0 \
   --served_model_name Qwen/Qwen3-Reranker-0.6B-v2-12000 \
   --max-model-len 8192

# éƒ¨ç½²åŸºç¤ Reranker æ¨¡å‹
vllm serve Qwen/Qwen3-Reranker-0.6B \
   --hf_overrides '{"architectures": ["Qwen3ForSequenceClassification"],"classifier_from_token": ["no", "yes"],"is_original_qwen3_reranker": true}' \
   --port 8001 \
   --host 0.0.0.0
```

### InfoNCE è³‡æ–™æ ¼å¼è¦ç¯„

#### æ ¼å¼
```json
# sample without rejected_response
{"query": "sentence1", "response": "sentence1-positive"}
# sample with multiple rejected_response
{"query": "sentence1", "response": "sentence1-positive", "rejected_response":  ["sentence1-negative1", "sentence1-negative2", ...]}
```

#### InfoNCE ç’°å¢ƒè®Šæ•¸è¨­å®š

InfoNCE loss æ”¯æ´ä»¥ä¸‹ç’°å¢ƒè®Šæ•¸ï¼š

- **INFONCE_TEMPERATURE**: æº«åº¦åƒæ•¸ã€‚è‹¥æœªè¨­å®šï¼Œé è¨­å€¼ç‚º 0.01
- **INFONCE_USE_BATCH**: æ±ºå®šæ˜¯å¦ä½¿ç”¨æ¨£æœ¬å…§çš„ rejected_responseï¼ˆhard negative samplesï¼‰æˆ–ä½¿ç”¨æ‰¹æ¬¡å…§çš„æ‰€æœ‰å›æ‡‰ã€‚é è¨­ç‚º Trueï¼Œè¡¨ç¤ºä½¿ç”¨æ‰¹æ¬¡å…§çš„å›æ‡‰
- **INFONCE_HARD_NEGATIVES**: hard negatives çš„æ•¸é‡ã€‚è‹¥æœªè¨­å®šï¼Œå°‡ä½¿ç”¨ rejected_response ä¸­çš„æ‰€æœ‰æ¨£æœ¬ã€‚ç”±æ–¼é•·åº¦å¯èƒ½ä¸ä¸€è‡´ï¼Œæœƒä½¿ç”¨ for è¿´åœˆè¨ˆç®—æå¤±ï¼ˆè¼ƒæ…¢ï¼‰ã€‚è‹¥è¨­å®šç‚ºç‰¹å®šæ•¸å€¼ï¼Œä¸”æ¨£æœ¬ä¸è¶³æ™‚ï¼Œæœƒéš¨æ©Ÿå–æ¨£è£œè¶³ï¼›è‹¥æ¨£æœ¬éå¤šï¼Œå‰‡æœƒé¸å–å‰ INFONCE_HARD_NEGATIVES å€‹
- **INFONCE_MASK_FAKE_NEGATIVE**: é®è”½å‡é™°æ€§æ¨£æœ¬ã€‚é è¨­ç‚º Falseã€‚å•Ÿç”¨æ™‚ï¼Œæœƒæª¢æŸ¥æ¨£æœ¬çš„ç›¸ä¼¼åº¦æ˜¯å¦å¤§æ–¼æ­£æ¨£æœ¬ç›¸ä¼¼åº¦åŠ  0.1ï¼Œè‹¥æ˜¯å‰‡å°‡è©²æ¨£æœ¬çš„ç›¸ä¼¼åº¦è¨­ç‚º -infï¼Œä»¥é˜²æ­¢æ­£æ¨£æœ¬æ´©æ¼

> **æ³¨æ„**: ä¹Ÿå¯ä»¥åœ¨è³‡æ–™é›†ä¸­è¨­å®šç›¸ç­‰çš„ hard negatives æ•¸é‡ï¼Œé€™æ¨£å³ä½¿æœªè¨­å®šä¹Ÿä¸æœƒä½¿ç”¨ for è¿´åœˆæ–¹æ³•ï¼Œå¾è€ŒåŠ é€Ÿè¨ˆç®—ã€‚
> 
> rejected_response ä¹Ÿå¯ä»¥çœç•¥ã€‚åœ¨æ­¤æƒ…æ³ä¸‹ï¼ŒINFONCE_USE_BATCH ä¿æŒç‚º Trueï¼Œæœƒä½¿ç”¨æ‰¹æ¬¡å…§çš„å…¶ä»–æ¨£æœ¬ä½œç‚º rejected responsesã€‚

#### InfoNCE è©•ä¼°æŒ‡æ¨™

InfoNCE loss çš„è©•ä¼°åŒ…å«ä»¥ä¸‹æŒ‡æ¨™ï¼š

- **mean_neg**: æ‰€æœ‰ hard negatives çš„å¹³å‡å€¼
- **mean_pos**: æ‰€æœ‰ positives çš„å¹³å‡å€¼  
- **margin**: (positive - max hard negative) çš„å¹³å‡å€¼

åƒè€ƒè³‡æ–™ï¼š[ms-swift InfoNCE æ ¼å¼æ–‡æª”](https://github.com/modelscope/ms-swift/blob/main/docs/source_en/BestPractices/Embedding.md#format-for-infonce)

## è³‡æ–™æº–å‚™å’Œè½‰æ›

### åŸå§‹è³‡æ–™é›†
æœ¬å°ˆæ¡ˆä½¿ç”¨[TCM-SD](https://github.com/Borororo/ZY-BERT)è³‡æ–™é›†ï¼ŒåŒ…å«ï¼š
- **train.jsonl**: 43,180 ç­†è¨“ç·´æ¡ˆä¾‹
- **test.jsonl**: 5,486 ç­†æ¸¬è©¦æ¡ˆä¾‹  
- **dev.jsonl**: 5,486 ç­†é©—è­‰è³‡æ–™
- **syndrome_knowledge.jsonl**: 1,027 ç­†ç—‡å€™çŸ¥è­˜
- **syndrome_vocab.txt**:148 ç­†ç—‡å€™è©

### è³‡æ–™è½‰æ›å·¥å…·

ä½¿ç”¨ `scripts/convert_to_infonce.py` å°‡åŸå§‹ç—…ä¾‹è³‡æ–™è½‰æ›ç‚ºé©åˆ InfoNCE è¨“ç·´çš„æ ¼å¼ï¼š

```bash
# è½‰æ›è¨“ç·´è³‡æ–™
uv run python scripts/convert_to_infonce.py \
    --input data/raw_data/TCM_SD/train.jsonl \
    --knowledge data/raw_data/TCM_SD/syndrome_knowledge.jsonl \
    --output data/train.jsonl

# é™åˆ¶æ¨£æœ¬æ•¸é‡ï¼ˆç”¨æ–¼æ¸¬è©¦ï¼‰
uv run python scripts/convert_to_infonce.py \
    --input data/raw_data/TCM_SD/train.jsonl \
    --knowledge data/raw_data/TCM_SD/syndrome_knowledge.jsonl \
    --output data/train_sample.jsonl \
    --max-samples 10
```

### è³‡æ–™æ ¼å¼è½‰æ›èªªæ˜

`convert_to_infonce.py` å°‡ TCM-SD ç—…ä¾‹è¨˜éŒ„è½‰æ›ç‚º InfoNCE è¨“ç·´æ ¼å¼ï¼š

**åŸºæœ¬è½‰æ›**ï¼š
- **query**: çµ„åˆã€Œä¸»è¨´ã€ã€ã€Œç¾ç—…å²ã€ã€ã€Œé«”æ ¼æª¢æŸ¥ã€ç­‰è‡¨åºŠè³‡è¨Š
- **response**: æ ¹æ“šè­‰å‹ï¼ˆsyndromeï¼‰åŒ¹é…çŸ¥è­˜åº«ï¼ŒåŒ…å«ã€Œåç¨±ã€ã€ã€Œå®šç¾©ã€ã€ã€Œå…¸å‹è¡¨ç¾ã€ã€ã€Œå¸¸è¦‹ç–¾ç—…ã€ç­‰

**æ•¸æ“šå¢å¼·é¸é …**ï¼š
- `--with-hard-negatives`: ä½¿ç”¨ BM25 ç”Ÿæˆç¡¬è² æ¨£æœ¬
- `--with-hard-negatives-custom-embedding`: ä½¿ç”¨è‡ªå®šç¾© Embedding API ç”Ÿæˆç¡¬è² æ¨£æœ¬
- `--hybrid`: æ··åˆè² æ¨£æœ¬ï¼ˆ2 éš¨æ©Ÿ + 3 BM25 + 3 Embeddingï¼‰
- `--split-negatives`: å°‡å¤šå€‹ rejected_response æ‹†åˆ†ç‚ºç¨ç«‹æ¨£æœ¬
- `--field-combinations`: ç”Ÿæˆ 11 ç¨®å­—æ®µçµ„åˆï¼ˆåç¨±ã€å®šç¾©ã€å…¸å‹è¡¨ç¾ç­‰çš„ä¸åŒçµ„åˆï¼‰
- `--field-permutations`: ç”Ÿæˆ 24 ç¨®å­—æ®µæ’åˆ—ï¼ˆæ‰€æœ‰å¯èƒ½çš„å­—æ®µé †åºï¼‰
- `--permutation-argument --multiplier N`: Zone-based æ’åˆ—å¢å¼·ï¼ˆN å€æ•¸æ“šï¼‰

**è¼¸å‡ºæ ¼å¼**ï¼š
```json
// æ¨™æº–æ ¼å¼
{"query": "ä¸»è¨´ï¼š...ç¾ç—…å²ï¼š...é«”æ ¼æª¢æŸ¥ï¼š...", "response": "åç¨±ï¼š...å®šç¾©ï¼š..."}

// å¸¶ç¡¬è² æ¨£æœ¬
{"query": "...", "response": "...", "rejected_response": ["...", "...", "..."]}
```
## é–‹ç™¼

### æœ¬åœ°é–‹ç™¼ ms-swift
```bash
# å¦‚éœ€ä¿®æ”¹ ms-swift æºç¢¼ï¼Œå¯å®‰è£æœ¬åœ°ç‰ˆæœ¬
uv pip install -e ../ms-swift
```

## å°ˆæ¡ˆçµæ§‹

```
TCMEmbeddingModel/
â”œâ”€â”€ README.md                                # å°ˆæ¡ˆèªªæ˜æ–‡ä»¶
â”œâ”€â”€ pyproject.toml                           # å°ˆæ¡ˆé…ç½®å’Œä¾è³´ç®¡ç† (uv)
â”œâ”€â”€ uv.lock                                  # uv ä¾è³´é–å®šæ–‡ä»¶
â”œâ”€â”€ data/                                    # è³‡æ–™ç›®éŒ„
â”‚   â”œâ”€â”€ raw_data/TCM_SD/                    # åŸå§‹ TCM-SD è³‡æ–™é›†
â”‚   â”‚   â”œâ”€â”€ train.jsonl                     # 43,180 ç­†è¨“ç·´æ¡ˆä¾‹
â”‚   â”‚   â”œâ”€â”€ dev.jsonl                       # 5,486 ç­†é©—è­‰æ¡ˆä¾‹
â”‚   â”‚   â”œâ”€â”€ test.jsonl                      # 5,486 ç­†æ¸¬è©¦æ¡ˆä¾‹
â”‚   â”‚   â”œâ”€â”€ syndrome_knowledge.jsonl        # 1,027 ç­†è­‰å‹çŸ¥è­˜
â”‚   â”‚   â””â”€â”€ syndrome_vocab.txt              # 148 å€‹è­‰å‹è©å½™
â”‚   â”œâ”€â”€ train.jsonl                         # è½‰æ›å¾Œçš„è¨“ç·´è³‡æ–™
â”‚   â”œâ”€â”€ dev.jsonl                           # è½‰æ›å¾Œçš„é©—è­‰è³‡æ–™
â”‚   â”œâ”€â”€ test.jsonl                          # è½‰æ›å¾Œçš„æ¸¬è©¦è³‡æ–™
â”‚   â”œâ”€â”€ train_with_hard_negatives.jsonl     # å¸¶ BM25 ç¡¬è² æ¨£æœ¬
â”‚   â”œâ”€â”€ train_hybrid.jsonl                  # æ··åˆç¡¬è² æ¨£æœ¬
â”‚   â”œâ”€â”€ train_field_combinations_*.jsonl    # å­—æ®µçµ„åˆå¢å¼·
â”‚   â””â”€â”€ train_permutation_argument_*.jsonl  # æ’åˆ—å¢å¼·
â”œâ”€â”€ scripts/                                 # å·¥å…·è…³æœ¬
â”‚   â”œâ”€â”€ convert_to_infonce.py               # è³‡æ–™è½‰æ›å·¥å…·ï¼ˆ1400+ è¡Œï¼‰
â”‚   â”œâ”€â”€ load_data.sh                        # è³‡æ–™è½‰æ›ç¯„ä¾‹è…³æœ¬
â”‚   â”œâ”€â”€ train.sh                            # Embedding è¨“ç·´è…³æœ¬
â”‚   â”œâ”€â”€ deploy.sh                           # Embedding éƒ¨ç½²è…³æœ¬
â”‚   â””â”€â”€ deploy_rerank.sh                    # Reranker éƒ¨ç½²è…³æœ¬
â”œâ”€â”€ output/                                  # è¨“ç·´è¼¸å‡º
â””â”€â”€ .venv/                                   # uv è™›æ“¬ç’°å¢ƒ (ä¸ç´å…¥ç‰ˆæ§)
```

## uv é…ç½®èªªæ˜

### pyproject.toml å¯¦éš›é…ç½®
```toml
[project]
name = "tcmembeddingmodel"
version = "0.1.0"
requires-python = ">=3.10"
dependencies = [
    "jieba>=0.42.1",        # ä¸­æ–‡åˆ†è©ï¼ˆç”¨æ–¼ BM25ï¼‰
    "ms-swift>=3.7.3",      # è¨“ç·´æ¡†æ¶
    "rank-bm25>=0.2.2",     # BM25 ç¡¬è² æ¨£æœ¬ç”Ÿæˆ
    "vllm>=0.10.1.1",       # æ¨ç†å¼•æ“
]
```

### ä¾è³´èªªæ˜
- **jieba**: ä¸­æ–‡åˆ†è©å·¥å…·ï¼Œç”¨æ–¼ BM25 ç¡¬è² æ¨£æœ¬ç”Ÿæˆ
- **ms-swift**: ModelScope SWIFT è¨“ç·´æ¡†æ¶ï¼ˆ>=3.7.3ï¼‰
- **rank-bm25**: BM25 æª¢ç´¢ç®—æ³•ï¼Œç”¨æ–¼ç”Ÿæˆç¡¬è² æ¨£æœ¬
- **vllm**: é«˜æ•ˆæ¨ç†å¼•æ“ï¼Œç”¨æ–¼æ¨¡å‹éƒ¨ç½²

## æŠ€è¡“åƒè€ƒæ–‡ä»¶
- [ms-swift Embedding æœ€ä½³å¯¦è¸](https://github.com/modelscope/ms-swift/blob/main/docs/source_en/BestPractices/Embedding.md)
- [Qwen3-Embedding SWIFT è¨“ç·´æ”¯æ´](https://github.com/QwenLM/Qwen3-Embedding/blob/main/docs/training/SWIFT.md#swift-training-support)
- [TCM-SD è³‡æ–™é›†è«–æ–‡](https://github.com/Borororo/ZY-BERT)
